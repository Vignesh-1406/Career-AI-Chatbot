# Career Advisor Chatbot using Gemini API

A production-ready, AI-powered career guidance chatbot built with Python, Streamlit, and Google Gemini API. Provides structured, practical, step-by-step career advice with multi-turn conversation support.

## üéØ Features

- **Intelligent Career Guidance**: Powered by Google's Gemini API with expertly-crafted system prompts
- **Multi-Turn Conversations**: Maintains context across multiple messages
- **Session Management**: Conversation history with optimization
- **Professional UI**: Clean Streamlit interface with chat-like experience
- **Production-Ready**: Clean architecture, comprehensive logging, error handling
- **Modular Design**: Separation of concerns with domain, service, and UI layers
- **Configuration Management**: Environment-based configuration with validation

## üèóÔ∏è Architecture

The project follows **Clean Architecture** principles:

```
chatbot/
‚îú‚îÄ‚îÄ app.py                          # UI Layer (Streamlit)
‚îú‚îÄ‚îÄ config.py                       # Configuration Management
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ gemini_service.py          # Gemini API Integration Layer
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îî‚îÄ‚îÄ system_prompt.py           # Prompt Engineering
‚îú‚îÄ‚îÄ memory/
‚îÇ   ‚îî‚îÄ‚îÄ session_memory.py          # Session State Management
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ logger.py                  # Logging Utility
‚îú‚îÄ‚îÄ requirements.txt                # Python Dependencies
‚îú‚îÄ‚îÄ .env.example                    # Environment Template
‚îî‚îÄ‚îÄ README.md                       # This file
```

### Architecture Layers

| Layer | File | Responsibility |
|-------|------|-----------------|
| **Presentation** | `app.py` | Streamlit UI, user interactions |
| **Application** | Services, Memory | Business logic orchestration |
| **Domain** | `services/gemini_api.py` | External API integration |
| **Infrastructure** | `config.py`, `utils/` | Configuration, logging |

## ‚ö° Quick Start

### Prerequisites

- Python 3.8+
- Google Gemini API key
- pip package manager

### Installation

1. **Clone or navigate to the project directory**

```bash
cd path/to/chatbot
```

2. **Create a virtual environment** (recommended)

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Set up environment configuration**

```bash
# Copy the example file
cp .env.example .env

# Edit .env and add your Gemini API key
# Get it from: https://aistudio.google.com/app/apikeys
```

5. **Run the application**

```bash
streamlit run app.py
```

The application will open in your browser at `http://localhost:8501`

## üîë Getting Gemini API Key

1. Visit [Google AI Studio](https://aistudio.google.com/app/apikeys)
2. Sign in with your Google account
3. Click "Create API Key"
4. Copy the key
5. Paste it in the `.env` file as `GEMINI_API_KEY=your_key_here`

## üìã Configuration

Edit `.env` file to customize:

```env
# API Configuration
GEMINI_API_KEY=your_api_key_here
GEMINI_MODEL=gemini-1.5-pro

# Response Behavior
TEMPERATURE=0.7          # 0=deterministic, 1=creative
MAX_TOKENS=1024         # Max response length

# Session Management
MAX_CONVERSATION_HISTORY=20
SESSION_TIMEOUT_MINUTES=30

# Logging
LOG_LEVEL=INFO
LOG_FILE=app.log
```

### Configuration Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `GEMINI_API_KEY` | - | Your API key (required) |
| `GEMINI_MODEL` | gemini-1.5-pro | AI model version |
| `TEMPERATURE` | 0.7 | Response creativity (0.0-1.0) |
| `MAX_TOKENS` | 1024 | Max response length |
| `MAX_CONVERSATION_HISTORY` | 20 | Messages to keep in memory |
| `LOG_LEVEL` | INFO | Logging detail level |

## üöÄ Usage

### Basic Usage

1. **Start the app** with `streamlit run app.py`
2. **Ask a career question** in the chat input
3. **Get AI-powered guidance** in real-time

### Example Prompts

- "Help me plan a career transition from finance to tech"
- "What skills do I need to become a data scientist?"
- "How do I prepare for a senior manager interview?"
- "Create a 12-month career development plan for me"
- "How can I negotiate a better salary?"

### Sidebar Features

- **Session Statistics**: View conversation metrics
- **API Status**: Check Gemini API connection
- **Test Connection**: Verify API configuration
- **Clear History**: Reset conversation
- **Export Conversation**: Download as JSON

## üìä Project Structure Details

### `app.py` - Streamlit UI Layer
- Page configuration and styling
- Session state management
- Chat interface rendering
- User input handling
- Response generation orchestration

### `config.py` - Configuration Management
- Environment variable loading
- Configuration validation
- Centralized settings management
- Default values with overrides

### `services/gemini_service.py` - API Integration
- Gemini API communication
- Error handling and retries
- Response processing
- Fallback responses
- API metrics logging

### `prompts/system_prompt.py` - Prompt Engineering
- System prompt definition
- Career advisor role specification
- Response format guidelines
- Domain constraints
- Request templates

### `memory/session_memory.py` - Session Management
- Conversation history tracking
- Multi-turn context preservation
- Memory optimization
- Session statistics
- Export/import functionality

### `utils/logger.py` - Logging Utility
- Centralized logging configuration
- File and console handlers
- Rotating file handler
- Structured logging methods
- API call tracking

## üîç Key Features Explained

### Multi-Turn Conversations

The chatbot maintains full conversation context:

```python
# System automatically maintains history
# Each response includes all previous messages
conversation_history = [
    {"role": "user", "content": "I want to switch careers"},
    {"role": "assistant", "content": "Great! Let's explore that..."},
    {"role": "user", "content": "I'm from finance"},
    # System remembers previous context
]
```

### Error Handling

Comprehensive error handling with fallback responses:

- API connection failures ‚Üí Graceful fallback
- Blocked prompts ‚Üí Safe user notification
- Invalid responses ‚Üí Retry or inform user
- Configuration errors ‚Üí Clear validation messages

### Session Memory Optimization

Automatically manages memory:

```python
# Keeps last N messages to prevent memory bloat
# Falls back to recent context if history too long
# Tracks session statistics and metrics
session_memory.optimize_memory()
```

## üß™ Testing

### Test API Connection

```bash
# From the Streamlit UI
Click "Test API Connection" in the sidebar
```

### Test Locally

```python
# Python shell test
from services.gemini_service import GeminiService

is_connected = GeminiService.test_connection()
print("Connected!" if is_connected else "Failed to connect")
```

## üìù Logging

Logs are written to `app.log`:

```
2025-02-18 10:30:45 - chatbot - INFO - Gemini API configured successfully
2025-02-18 10:31:20 - chatbot - INFO - User Interaction - Message Length: 45
2025-02-18 10:31:25 - chatbot - DEBUG - API Metrics - Input: 234, Output: 567
```

View logs:
```bash
tail -f app.log        # macOS/Linux
Get-Content app.log -Tail 10 -Wait  # Windows PowerShell
```

## üõ†Ô∏è Development

### Adding New Features

1. **Add to appropriate layer** (UI ‚Üí app.py, API ‚Üí services, Config ‚Üí config.py)
2. **Follow existing patterns** (logging, error handling, type hints)
3. **Add comprehensive docstrings** with Args, Returns, Raises
4. **Update this README** with new usage examples
5. **Test thoroughly** with various inputs

### Extending the Chatbot

#### Add New Career Guidance Module

```python
# In prompts/system_prompt.py
class NewGuidanceModule:
    PROMPT = "Your specialized prompt here..."
    
    @staticmethod
    def get_prompt():
        return NewGuidanceModule.PROMPT
```

#### Add Custom Response Processing

```python
# In services/gemini_service.py
def process_response(self, response):
    # Add custom processing logic
    return processed_response
```

## ‚ö†Ô∏è Important Notes

### Security

- **Never commit `.env` file** to version control
- **Rotate API keys** regularly
- **Use environment variables** for all secrets
- **Request logging** doesn't log sensitive data by default

### Rate Limiting

- **Free tier**: Limited requests per minute
- **Monitor logs** for rate limit errors
- **Use `MAX_CONVERSATION_HISTORY`** to control token usage

### Best Practices

1. ‚úÖ Keep API key in `.env`, never hardcode
2. ‚úÖ Use virtual environment for dependencies
3. ‚úÖ Review logs regularly for errors
4. ‚úÖ Optimize conversation history for performance
5. ‚úÖ Test configuration before deployment

## üêõ Troubleshooting

### "GEMINI_API_KEY not set" Error

```bash
# Solution: Make sure .env file exists and has API key
cp .env.example .env
# Edit .env with your actual API key
```

### API Connection Fails

```bash
# Check API key is correct
# Verify internet connection
# Try test connection button in sidebar
# Check logs: tail -f app.log
```

### Empty Response from API

```bash
# Check logs for error details
# Verify model name is correct in .env
# Try simpler test question
# Increase MAX_TOKENS if response cuts off
```

### High Token Usage

```bash
# Reduce MAX_CONVERSATION_HISTORY
# Decrease MAX_TOKENS
# Clear history frequently
```

## üìö Resources

- [Google Gemini API](https://ai.google.dev/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Python dotenv Guide](https://github.com/theskumar/python-dotenv)
- [Clean Architecture](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)

## ü§ù Contributing

To enhance this project:

1. Follow the existing code structure
2. Add comprehensive error handling
3. Include logging for debugging
4. Update README with changes
5. Test thoroughly before committing

## üìÑ License

This project is provided as-is for educational and development purposes.

## üéì Learning Outcomes

This project demonstrates:

- Clean Architecture principles
- API integration best practices
- Session/state management
- Error handling and logging
- Environment configuration
- Streamlit UI development
- Production-ready code standards

---

**Need Help?**
- Check the [Troubleshooting](#-troubleshooting) section
- Review logs in `app.log`
- Verify your `.env` configuration
- Test API connection from the sidebar

**Last Updated**: February 2025
